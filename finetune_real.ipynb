{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fine-Tuning Baseline Model on Small Real Dataset\n",
    "\n",
    "This notebook fine-tunes the pretrained ResNet18 baseline model on a small labeled real dataset to improve real-domain accuracy."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "import os\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torchvision import datasets, transforms, models\n",
    "from torch.utils.data import DataLoader\n",
    "import copy\n",
    "\n",
    "# Paths\n",
    "REAL_TRAIN_DIR = 'data/real/train'   # Small labeled real training data\n",
    "REAL_VAL_DIR = 'data/real/val'\n",
    "BATCH_SIZE = 16\n",
    "NUM_EPOCHS = 10\n",
    "LEARNING_RATE = 1e-4\n",
    "DEVICE = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "PRETRAINED_MODEL_PATH = 'baseline_resnet18.pth'\n",
    "FINETUNED_MODEL_PATH = 'finetuned_real_resnet18.pth'"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# Data Transforms\n",
    "train_transform = transforms.Compose([\n",
    "    transforms.Resize((224,224)),\n",
    "    transforms.RandomHorizontalFlip(),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485,0.456,0.406], std=[0.229,0.224,0.225])\n",
    "])\n",
    "\n",
    "val_transform = transforms.Compose([\n",
    "    transforms.Resize((224,224)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485,0.456,0.406], std=[0.229,0.224,0.225])\n",
    "])\n",
    "\n",
    "# Datasets & Loaders\n",
    "train_dataset = datasets.ImageFolder(REAL_TRAIN_DIR, transform=train_transform)\n",
    "val_dataset = datasets.ImageFolder(REAL_VAL_DIR, transform=val_transform)\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True)\n",
    "val_loader = DataLoader(val_dataset, batch_size=BATCH_SIZE, shuffle=False)\n",
    "\n",
    "classes = train_dataset.classes\n",
    "print(f'Classes: {classes}')"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# Load pretrained baseline model\n",
    "model = models.resnet18(pretrained=False)\n",
    "model.fc = nn.Linear(model.fc.in_features, len(classes))\n",
    "model.load_state_dict(torch.load(PRETRAINED_MODEL_PATH, map_location=DEVICE))\n",
    "model = model.to(DEVICE)"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# Freeze earlier layers (optional) and train only classifier\n",
    "for param in model.parameters():\n",
    "    param.requires_grad = True  # or freeze backbone if desired\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=LEARNING_RATE)"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "best_acc = 0.0\n",
    "best_model_wts = copy.deepcopy(model.state_dict())\n",
    "\n",
    "for epoch in range(1, NUM_EPOCHS+1):\n",
    "    print(f'\\nEpoch {epoch}/{NUM_EPOCHS}')\n",
    "    print('-'*20)\n",
    "    \n",
    "    # Training\n",
    "    model.train()\n",
    "    running_loss = 0.0\n",
    "    running_corrects = 0\n",
    "    \n",
    "    for inputs, labels in train_loader:\n",
    "        inputs, labels = inputs.to(DEVICE), labels.to(DEVICE)\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(inputs)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        _, preds = torch.max(outputs,1)\n",
    "        running_loss += loss.item() * inputs.size(0)\n",
    "        running_corrects += torch.sum(preds == labels.data)\n",
    "    \n",
    "    epoch_loss = running_loss / len(train_dataset)\n",
    "    epoch_acc = running_corrects.double() / len(train_dataset)\n",
    "    print(f'Train Loss: {epoch_loss:.4f} | Train Acc: {epoch_acc:.4f}')\n",
    "    \n",
    "    # Validation\n",
    "    model.eval()\n",
    "    val_loss = 0.0\n",
    "    val_corrects = 0\n",
    "    with torch.no_grad():\n",
    "        for inputs, labels in val_loader:\n",
    "            inputs, labels = inputs.to(DEVICE), labels.to(DEVICE)\n",
    "            outputs = model(inputs)\n",
    "            loss = criterion(outputs, labels)\n",
    "            _, preds = torch.max(outputs,1)\n",
    "            val_loss += loss.item() * inputs.size(0)\n",
    "            val_corrects += torch.sum(preds == labels.data)\n",
    "    val_loss = val_loss / len(val_dataset)\n",
    "    val_acc = val_corrects.double() / len(val_dataset)\n",
    "    print(f'Val Loss: {val_loss:.4f} | Val Acc: {val_acc:.4f}')\n",
    "    \n",
    "    if val_acc > best_acc:\n",
    "        best_acc = val_acc\n",
    "        best_model_wts = copy.deepcopy(model.state_dict())\n",
    "        torch.save(model.state_dict(), FINETUNED_MODEL_PATH)\n",
    "        print(f'Saved best fine-tuned model with Val Acc: {best_acc:.4f}')\n",
    "\n",
    "print(f'\\nFine-tuning complete. Best Val Acc: {best_acc:.4f}')"
   ]
  }
 ]
}

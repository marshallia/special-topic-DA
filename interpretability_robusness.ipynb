{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Interpretability & Robustness Analysis\n",
    "\n",
    "This notebook analyzes the trained models using Grad-CAM for interpretability and evaluates robustness to input perturbations."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torchvision import transforms, datasets, models\n",
    "from torch.utils.data import DataLoader\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import cv2\n",
    "from PIL import Image\n",
    "import random"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Configuration"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# Model paths\n",
    "MODEL_PATH = 'baseline_resnet18.pth'  # Change to DANN/CDAN model if desired\n",
    "REAL_TEST_DIR = 'data/real/test'\n",
    "BATCH_SIZE = 16\n",
    "DEVICE = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# Data loader\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize((224,224)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize([0.485,0.456,0.406],[0.229,0.224,0.225])\n",
    "])\n",
    "test_dataset = datasets.ImageFolder(REAL_TEST_DIR, transform=transform)\n",
    "test_loader = DataLoader(test_dataset, batch_size=BATCH_SIZE, shuffle=False)\n",
    "classes = test_dataset.classes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Load Pretrained Model"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "model = models.resnet18(pretrained=False)\n",
    "model.fc = nn.Linear(model.fc.in_features, len(classes))\n",
    "model.load_state_dict(torch.load(MODEL_PATH, map_location=DEVICE))\n",
    "model = model.to(DEVICE)\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Interpretability using Grad-CAM"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "def generate_gradcam(model, image, target_class):\n",
    "    model.eval()\n",
    "    gradients = []\n",
    "    activations = []\n",
    "    \n",
    "    def backward_hook(module, grad_input, grad_output):\n",
    "        gradients.append(grad_output[0])\n",
    "        \n",
    "    def forward_hook(module, input, output):\n",
    "        activations.append(output)\n",
    "        \n",
    "    # Attach hooks to last conv layer\n",
    "    for name, module in model.named_modules():\n",
    "        if isinstance(module, nn.Conv2d):\n",
    "            target_layer = module\n",
    "    \n",
    "    handle_fw = target_layer.register_forward_hook(forward_hook)\n",
    "    handle_bw = target_layer.register_backward_hook(backward_hook)\n",
    "    \n",
    "    image = image.unsqueeze(0).to(DEVICE)\n",
    "    output = model(image)\n",
    "    loss = output[0, target_class]\n",
    "    model.zero_grad()\n",
    "    loss.backward()\n",
    "    \n",
    "    grads = gradients[0].cpu().data.numpy()[0]\n",
    "    acts = activations[0].cpu().data.numpy()[0]\n",
    "    weights = np.mean(grads, axis=(1,2))\n",
    "    cam = np.zeros(acts.shape[1:], dtype=np.float32)\n",
    "    for i, w in enumerate(weights):\n",
    "        cam += w * acts[i, :, :]\n",
    "    cam = np.maximum(cam, 0)\n",
    "    cam = cv2.resize(cam, (224,224))\n",
    "    cam = cam - np.min(cam)\n",
    "    cam = cam / np.max(cam)\n",
    "    \n",
    "    handle_fw.remove()\n",
    "    handle_bw.remove()\n",
    "    return cam"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# Show Grad-CAM for random samples\n",
    "num_samples = 3\n",
    "indices = random.sample(range(len(test_dataset)), num_samples)\n",
    "\n",
    "for idx in indices:\n",
    "    img, label = test_dataset[idx]\n",
    "    cam = generate_gradcam(model, img, label)\n",
    "    img_np = np.transpose(img.numpy(), (1,2,0))\n",
    "    img_np = (img_np * [0.229,0.224,0.225]) + [0.485,0.456,0.406]  # denormalize\n",
    "    img_np = np.clip(img_np, 0, 1)\n",
    "    \n",
    "    plt.figure(figsize=(6,6))\n",
    "    plt.imshow(img_np)\n",
    "    plt.imshow(cam, cmap='jet', alpha=0.5)\n",
    "    plt.title(f'True class: {classes[label]}')\n",
    "    plt.axis('off')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Robustness Analysis"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "def perturb_image(img, noise_level=0.1, blur_kernel=3, brightness_factor=1.2):\n",
    "    img_np = np.transpose(img.numpy(), (1,2,0))\n",
    "    img_np = (img_np * [0.229,0.224,0.225]) + [0.485,0.456,0.406]\n",
    "    img_np = np.clip(img_np, 0, 1)\n",
    "    img_np = (img_np*255).astype(np.uint8)\n",
    "    img_cv = cv2.cvtColor(img_np, cv2.COLOR_RGB2BGR)\n",
    "    # Add noise\n",
    "    noise = np.random.randn(*img_cv.shape) * noise_level * 255\n",
    "    img_cv = np.clip(img_cv + noise, 0, 255).astype(np.uint8)\n",
    "    # Blur\n",
    "    img_cv = cv2.GaussianBlur(img_cv, (blur_kernel, blur_kernel), 0)\n",
    "    # Brightness\n",
    "    img_cv = cv2.convertScaleAbs(img_cv, alpha=brightness_factor, beta=0)\n",
    "    img_cv = cv2.cvtColor(img_cv, cv2.COLOR_BGR2RGB)\n",
    "    img_cv = img_cv.astype(np.float32)/255.0\n",
    "    img_tensor = torch.tensor(np.transpose(img_cv,(2,0,1)), dtype=torch.float32)\n",
    "    img_tensor = transforms.Normalize([0.485,0.456,0.406],[0.229,0.224,0.225])(img_tensor)\n",
    "    return img_tensor"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# Evaluate robustness on a subset\n",
    "num_test = 50\n",
    "indices = random.sample(range(len(test_dataset)), num_test)\n",
    "correct = 0\n",
    "\n",
    "for idx in indices:\n",
    "    img, label = test_dataset[idx]\n",
    "    perturbed_img = perturb_image(img)\n",
    "    perturbed_img = perturbed_img.unsqueeze(0).to(DEVICE)\n",
    "    with torch.no_grad():\n",
    "        output = model(perturbed_img)\n",
    "        _, pred = torch.max(output,1)\n",
    "        if pred.item() == label:\n",
    "            correct +=1\n",
    "\n",
    "robust_acc = correct / num_test\n",
    "print(f'Robustness Accuracy under perturbations: {robust_acc:.4f}')"
   ]
  }
 ]
}
